{"cells":[{"metadata":{},"cell_type":"markdown","source":"# Imports"},{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Globals"},{"metadata":{"trusted":true},"cell_type":"code","source":"FEATURES_CSV = '../input/jane-street-market-prediction/features.csv'\nTRAIN_CSV = '../input/jane-street-market-prediction/train.csv'\nTEST_CSV = '../input/jane-street-market-prediction/example_test.csv'\nVAL = False","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Read DS"},{"metadata":{"trusted":true},"cell_type":"code","source":"feat = pd.read_csv(FEATURES_CSV)\ntr = pd.read_csv(TRAIN_CSV)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Look at the data"},{"metadata":{},"cell_type":"markdown","source":"## Features"},{"metadata":{"trusted":true},"cell_type":"code","source":"feat.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print('Anonymous Features: {} rows, {} columns'.format(len(feat),len(feat.columns)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.info()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"tr.columns","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Preprocess"},{"metadata":{"trusted":true},"cell_type":"code","source":"def preprocess(ds):\n    ds = ds.loc[ds.weight>0] # these entries are not useful \n    ds = ds.dropna() #ignoring NAs for now\n    len(ds)\n    return ds","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Let's ANALYZZEE!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"len(tr)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for column in tr.columns:\n#     print(column, tr[column].nunique())","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tr['date'].unique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# tr['resp'].nunique()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"print(float(tr.loc[tr.resp>0]['resp'].nunique()/len(tr)))\nprint(float(tr.loc[tr.resp_1>0]['resp_1'].nunique()/len(tr)))\nprint(float(tr.loc[tr.resp_2>0]['resp_2'].nunique()/len(tr)))\nprint(float(tr.loc[tr.resp_3>0]['resp_3'].nunique()/len(tr)))\nprint(float(tr.loc[tr.resp_4>0]['resp_4'].nunique()/len(tr)))","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"## ~ 50% of the responses have >0 (can do the trade)"},{"metadata":{},"cell_type":"markdown","source":"# Prep for Train"},{"metadata":{"trusted":true},"cell_type":"code","source":"resp_cols = ['resp','resp_1','resp_2','resp_3','resp_4']\nfeatures = [c for c in tr.columns if 'feature' in c]\nf_mean = np.mean(tr[features[1:]].values, axis=0)\ntr = preprocess(tr)\nsplit_num = int(0.7*tr.date.nunique())\n# print(split_num)\n\nif VAL:\n    tr_tr = tr.loc[tr.date<=split_num]\n    x_train = tr_tr.loc[:,tr_tr.columns.str.contains('feature')]\n    y_train = np.stack([(tr_tr[c] > 0).astype('int') for c in resp_cols]).T\n\n    te = tr.loc[tr.date>split_num]\n    x_test = te.loc[:,te.columns.str.contains('feature')]\n    y_test = np.stack([(te[c] > 0).astype('int') for c in resp_cols]).T\nelse:\n    x_train = tr.loc[:,tr.columns.str.contains('feature')]\n    y_train = np.stack([(tr[c] > 0).astype('int') for c in resp_cols]).T\n","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"resp_cols = ['resp', 'resp_1', 'resp_2', 'resp_3', 'resp_4']\nprint(len([(tr[c] > 0).astype('int') for c in resp_cols]))\nprint(np.stack([(tr[c] > 0).astype('int') for c in resp_cols]).shape)\nprint(np.stack([(tr[c] > 0).astype('int') for c in resp_cols]).T.shape)\nprint(np.stack([(tr[c] > 0).astype('int') for c in resp_cols]).T)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train.head()","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(x_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"len(y_train)","execution_count":null,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train[:,0].shape","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Train!!"},{"metadata":{"trusted":true},"cell_type":"code","source":"models = []\n\nfor i in range(len(resp_cols)):\n    print('\\n\\n',i)\n    logreg = LogisticRegression(max_iter=500)\n    logreg.fit(x_train, y_train[:,i])\n    models.append(logreg)","execution_count":null,"outputs":[]},{"metadata":{},"cell_type":"markdown","source":"# Predict"},{"metadata":{"trusted":true},"cell_type":"code","source":"if VAL:\n    for i,model in enumerate(models):\n        y_pred = model.predict(x_test)\n        print('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(x_test, y_test[:,i])))\n        confusion_matrix = metrics.confusion_matrix(y_test[:,i], y_pred)\n        print('Confusion Matrix:',confusion_matrix)\n\nelse:\n    th = 0.502\n    f = np.median\n\n    import janestreet\n    env = janestreet.make_env() # initialize the environment\n\n    iter_test = env.iter_test() # an iterator which loops over the test set\n\n    for (test_df, sample_prediction_df) in iter_test:\n        if test_df['weight'].item() > 0:\n            x_tt = test_df.loc[:, features].values\n            if np.isnan(x_tt[:, 1:].sum()):\n                x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n            x_tt = np.nan_to_num(x_tt)\n            pred = np.mean([model.predict(x_tt) for model in models], axis=0)\n            pred = f(pred)\n            sample_prediction_df.action = np.where(pred >= th, 1, 0).astype(int)\n        else:\n            sample_prediction_df.action = 0\n        env.predict(sample_prediction_df)","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat":4,"nbformat_minor":4}